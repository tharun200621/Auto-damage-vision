{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ff7a4e-ad82-43f1-92b2-3d571eb6ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import required libraries\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a7560b-c184-4706-b44e-8f8592ef6eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Step 1: Load Trained Model\n",
    "# ------------------------------------------\n",
    "\n",
    "# Path to trained model weights\n",
    "MODEL_PATH = \"training_outputs/best_model.pt\"\n",
    "\n",
    "# Load trained YOLO model\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "print(\"Trained model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef6d5356-e0c7-4bf9-9654-823dccc01be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on images: ['000001.jpg', '000053.jpg', '000102.jpg', '000111.jpg', '000292.jpg']\n",
      "Inference completed!\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Step 2: Run Inference on Validation Images\n",
    "# ------------------------------------------\n",
    "\n",
    "# Path to validation images\n",
    "VAL_IMAGES_DIR = \"yolo_dataset/images/val\"\n",
    "\n",
    "# Select a few validation images for inference\n",
    "val_images = os.listdir(VAL_IMAGES_DIR)\n",
    "sample_images = val_images[:5]  # take first 5 images\n",
    "\n",
    "print(\"Running inference on images:\", sample_images)\n",
    "\n",
    "# Run inference\n",
    "results = model.predict(\n",
    "    source=[os.path.join(VAL_IMAGES_DIR, img) for img in sample_images],\n",
    "    conf=0.25,\n",
    "    device=0,\n",
    "    stream=True,\n",
    "    save=False\n",
    ")\n",
    "\n",
    "print(\"Inference completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f4a0331-e168-412a-9574-9fa5f686f8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction folder: runs/detect\\val5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Step 3: Visualize Predictions\n",
    "# ------------------------------------------\n",
    "\n",
    "# YOLO saves prediction images automatically inside runs/detect/predict*\n",
    "# We will load and display them.\n",
    "\n",
    "# Find latest prediction folder\n",
    "PREDICT_DIR = \"runs/detect\"\n",
    "latest_predict = sorted(os.listdir(PREDICT_DIR))[-1]\n",
    "predict_path = os.path.join(PREDICT_DIR, latest_predict)\n",
    "\n",
    "print(\"Prediction folder:\", predict_path)\n",
    "\n",
    "# Display predicted images\n",
    "pred_images = os.listdir(predict_path)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "for i, img_name in enumerate(pred_images[:5]):\n",
    "    img_path = os.path.join(predict_path, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(img_name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b36bec-de9d-46e3-9870-761e02882dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.250  Python-3.12.10 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 104.370.1 MB/s, size: 702.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\self-learning\\tharun\\yolo_dataset\\labels\\val.cache... 0 images, 76 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 76/76  0.0s\n",
      "WARNING Labels are missing or empty in E:\\self-learning\\tharun\\yolo_dataset\\labels\\val.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 2.5it/s 2.0s0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubh Sareen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ultralytics\\utils\\metrics.py:654: RuntimeWarning: Mean of empty slice.\n",
      "  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n",
      "C:\\Users\\Shubh Sareen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Shubh Sareen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ultralytics\\utils\\metrics.py:700: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "C:\\Users\\Shubh Sareen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "C:\\Users\\Shubh Sareen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ultralytics\\utils\\metrics.py:700: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "C:\\Users\\Shubh Sareen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "C:\\Users\\Shubh Sareen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ultralytics\\utils\\metrics.py:700: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "C:\\Users\\Shubh Sareen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "C:\\Users\\Shubh Sareen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ultralytics\\utils\\metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76          0          0          0          0          0\n",
      "WARNING no labels found in detect set, cannot compute metrics without labels\n",
      "Speed: 0.6ms preprocess, 5.3ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1mE:\\self-learning\\tharun\\runs\\detect\\val6\u001b[0m\n",
      "\n",
      "===== Evaluation Metrics =====\n",
      "Precision: 0.0\n",
      "mAP@0.5: 0.0\n",
      "mAP@0.5:0.95: 0.0\n",
      "\n",
      "===== Metric Interpretation =====\n",
      "IoU (Intersection over Union): Measures how well predicted boxes overlap ground truth.\n",
      "Precision: Fraction of predicted boxes that are correct.\n",
      "Recall: Fraction of ground-truth boxes that were detected.\n",
      "mAP@0.5: Mean Average Precision at IoU threshold 0.5.\n",
      "mAP@0.5:0.95: Mean Average Precision averaged across multiple IoU thresholds.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Step 4: Understanding Metrics\n",
    "# ------------------------------------------\n",
    "\n",
    "# Run evaluation on validation set\n",
    "metrics = model.val(data=\"yolo_dataset/data.yaml\", workers=0)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\n===== Evaluation Metrics =====\")\n",
    "print(\"Precision:\", metrics.box.map50)   # mAP@0.5 (proxy for precision/recall balance)\n",
    "print(\"mAP@0.5:\", metrics.box.map50)\n",
    "print(\"mAP@0.5:0.95:\", metrics.box.map)\n",
    "\n",
    "print(\"\\n===== Metric Interpretation =====\")\n",
    "print(\"IoU (Intersection over Union): Measures how well predicted boxes overlap ground truth.\")\n",
    "print(\"Precision: Fraction of predicted boxes that are correct.\")\n",
    "print(\"Recall: Fraction of ground-truth boxes that were detected.\")\n",
    "print(\"mAP@0.5: Mean Average Precision at IoU threshold 0.5.\")\n",
    "print(\"mAP@0.5:0.95: Mean Average Precision averaged across multiple IoU thresholds.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
