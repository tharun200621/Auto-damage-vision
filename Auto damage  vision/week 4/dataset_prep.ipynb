{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d361ae-7ad5-4631-838e-06975262881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import required libraries\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e56987fa-0254-43fb-afa8-04be4a025bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset Root: ./CarDD_release/CarDD_release/CarDD_COCO\n",
      " Training Images: 2816\n",
      " Validation Images: 810\n",
      " Annotation Files: ['image_info.xlsx', 'instances_test2017.json', 'instances_train2017.json', 'instances_val2017.json']\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Step 1: Dataset Overview\n",
    "# ------------------------------------------\n",
    "\n",
    "# Define dataset root directory (Windows path)\n",
    "DATASET_ROOT = r\"./CarDD_release/CarDD_release/CarDD_COCO\"\n",
    "\n",
    "TRAIN_IMAGES_DIR = os.path.join(DATASET_ROOT, \"train2017\")\n",
    "VAL_IMAGES_DIR = os.path.join(DATASET_ROOT, \"val2017\")\n",
    "ANNOTATIONS_DIR = os.path.join(DATASET_ROOT, \"annotations\")\n",
    "\n",
    "# Inspect available images\n",
    "train_images = os.listdir(TRAIN_IMAGES_DIR)\n",
    "val_images = os.listdir(VAL_IMAGES_DIR)\n",
    "\n",
    "# Inspect annotations\n",
    "annotations_files = os.listdir(ANNOTATIONS_DIR)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(\" Dataset Root:\", DATASET_ROOT)\n",
    "print(\" Training Images:\", len(train_images))\n",
    "print(\" Validation Images:\", len(val_images))\n",
    "print(\" Annotation Files:\", annotations_files)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b012c7f-9947-4313-9f92-0cf4d8476f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Training Samples: 300\n",
      "Selected Validation Samples: 80\n",
      "\n",
      "Sample training images: ['003501.jpg', '003207.jpg', '003104.jpg', '002649.jpg', '000349.jpg']\n",
      "Sample validation images: ['001494.jpg', '002625.jpg', '000825.jpg', '003127.jpg', '000187.jpg']\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Step 2: Subset Selection\n",
    "# ------------------------------------------\n",
    "\n",
    "# Number of samples to use\n",
    "NUM_TRAIN_SAMPLES = 300\n",
    "NUM_VAL_SAMPLES = 80\n",
    "\n",
    "# Random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Shuffle image lists\n",
    "random.shuffle(train_images)\n",
    "random.shuffle(val_images)\n",
    "\n",
    "# Select subsets\n",
    "train_subset = train_images[:NUM_TRAIN_SAMPLES]\n",
    "val_subset = val_images[:NUM_VAL_SAMPLES]\n",
    "\n",
    "# Store selected file names\n",
    "print(\"Selected Training Samples:\", len(train_subset))\n",
    "print(\"Selected Validation Samples:\", len(val_subset))\n",
    "\n",
    "# Show a few sample names\n",
    "print(\"\\nSample training images:\", train_subset[:5])\n",
    "print(\"Sample validation images:\", val_subset[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b1c5baa-2516-44c1-87e5-724323d947ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Images: 304\n",
      "Final Validation Images: 76\n",
      "\n",
      "Train sample: ['003966.jpg', '003594.jpg', '002499.jpg', '002599.jpg', '002239.jpg']\n",
      "Val sample: ['000460.jpg', '003207.jpg', '000455.jpg', '003709.jpg', '003180.jpg']\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Step 3: Train / Validation Split\n",
    "# ------------------------------------------\n",
    "\n",
    "# Combine all selected images\n",
    "all_selected_images = train_subset + val_subset\n",
    "\n",
    "# Shuffle again before split\n",
    "random.shuffle(all_selected_images)\n",
    "\n",
    "# 80/20 split\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(all_selected_images) * split_ratio)\n",
    "\n",
    "final_train_images = all_selected_images[:split_index]\n",
    "final_val_images = all_selected_images[split_index:]\n",
    "\n",
    "print(\"Final Training Images:\", len(final_train_images))\n",
    "print(\"Final Validation Images:\", len(final_val_images))\n",
    "\n",
    "# Preview filenames\n",
    "print(\"\\nTrain sample:\", final_train_images[:5])\n",
    "print(\"Val sample:\", final_val_images[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdafe190-1299-448f-8ea8-8e1c2d7fe330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder structure:\n",
      "yolo_dataset\\images/train\n",
      "yolo_dataset\\images/val\n",
      "yolo_dataset\\labels/train\n",
      "yolo_dataset\\labels/val\n",
      "Images copied successfully!\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Step 4: Folder Structure Creation\n",
    "# ------------------------------------------\n",
    "\n",
    "# Output dataset root\n",
    "OUTPUT_ROOT = \"yolo_dataset\"\n",
    "\n",
    "# Define folders\n",
    "IMAGES_TRAIN_DIR = os.path.join(OUTPUT_ROOT, \"images/train\")\n",
    "IMAGES_VAL_DIR = os.path.join(OUTPUT_ROOT, \"images/val\")\n",
    "LABELS_TRAIN_DIR = os.path.join(OUTPUT_ROOT, \"labels/train\")\n",
    "LABELS_VAL_DIR = os.path.join(OUTPUT_ROOT, \"labels/val\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(IMAGES_TRAIN_DIR, exist_ok=True)\n",
    "os.makedirs(IMAGES_VAL_DIR, exist_ok=True)\n",
    "os.makedirs(LABELS_TRAIN_DIR, exist_ok=True)\n",
    "os.makedirs(LABELS_VAL_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Created folder structure:\")\n",
    "print(IMAGES_TRAIN_DIR)\n",
    "print(IMAGES_VAL_DIR)\n",
    "print(LABELS_TRAIN_DIR)\n",
    "print(LABELS_VAL_DIR)\n",
    "\n",
    "# Create lookup sets\n",
    "train_set = set(train_images)\n",
    "val_set = set(val_images)\n",
    "\n",
    "# Copy training images (from correct source)\n",
    "for img_name in final_train_images:\n",
    "    if img_name in train_set:\n",
    "        src_path = os.path.join(TRAIN_IMAGES_DIR, img_name)\n",
    "    else:\n",
    "        src_path = os.path.join(VAL_IMAGES_DIR, img_name)\n",
    "\n",
    "    dst_path = os.path.join(IMAGES_TRAIN_DIR, img_name)\n",
    "    shutil.copy(src_path, dst_path)\n",
    "\n",
    "# Copy validation images (from correct source)\n",
    "for img_name in final_val_images:\n",
    "    if img_name in train_set:\n",
    "        src_path = os.path.join(TRAIN_IMAGES_DIR, img_name)\n",
    "    else:\n",
    "        src_path = os.path.join(VAL_IMAGES_DIR, img_name)\n",
    "\n",
    "    dst_path = os.path.join(IMAGES_VAL_DIR, img_name)\n",
    "    shutil.copy(src_path, dst_path)\n",
    "\n",
    "print(\"Images copied successfully!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c134099-6e21-497d-acc4-807139f216a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhy is data cleanliness important for training?\\n\\nData cleanliness is important because the model learns directly from the data.\\nIf the dataset contains noisy, duplicated, corrupted, or wrongly labeled samples,\\nthe model will learn incorrect patterns and perform poorly in real-world scenarios.\\nClean data leads to stable training, faster convergence, and better generalization.\\n\\nIn object detection, even small errors in labels can significantly affect model accuracy.\\n\\n\\nWhat could go wrong with bad annotations?\\n\\nBad annotations can cause:\\n1. Incorrect bounding boxes, leading to poor object localization and low IoU.\\n2. Wrong class labels, causing class confusion and misclassification.\\n3. Missing annotations, which reduce recall because damaged regions are treated as background.\\n4. Loose or oversized boxes, which include background and reduce detection precision.\\n\\nA detection model is only as good as its annotations.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Reflection\n",
    "# ------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "Why is data cleanliness important for training?\n",
    "\n",
    "Data cleanliness is important because the model learns directly from the data.\n",
    "If the dataset contains noisy, duplicated, corrupted, or wrongly labeled samples,\n",
    "the model will learn incorrect patterns and perform poorly in real-world scenarios.\n",
    "Clean data leads to stable training, faster convergence, and better generalization.\n",
    "\n",
    "In object detection, even small errors in labels can significantly affect model accuracy.\n",
    "\n",
    "\n",
    "What could go wrong with bad annotations?\n",
    "\n",
    "Bad annotations can cause:\n",
    "1. Incorrect bounding boxes, leading to poor object localization and low IoU.\n",
    "2. Wrong class labels, causing class confusion and misclassification.\n",
    "3. Missing annotations, which reduce recall because damaged regions are treated as background.\n",
    "4. Loose or oversized boxes, which include background and reduce detection precision.\n",
    "\n",
    "A detection model is only as good as its annotations.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb458d9-b549-42a3-bcbf-378a85d82cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
