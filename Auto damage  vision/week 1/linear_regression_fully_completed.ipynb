{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINEAR REGRESSION\n",
    "In this assignment we try to model the 'Estimated Price' as a linear relation of the other elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSES IN PYTHON\n",
    "Although this might look scary to implement, go about it one function at a time.  \n",
    "Using classes help with keeping track of multiple models and makes your overall code much tidier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self) -> None:\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X @ self.weights + self.bias\n",
    "\n",
    "    def fit(self, X, y, epochs=1000, learning_rate=0.01, norm=2, threshold=1e-6, lambda_reg=0.0):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0.0\n",
    "\n",
    "        prev_loss = float('inf')\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            y_pred = self.predict(X)\n",
    "            error = y_pred - y\n",
    "\n",
    "            dw = (1 / n_samples) * (X.T @ error)\n",
    "            db = (1 / n_samples) * error.sum()\n",
    "\n",
    "            if lambda_reg > 0:\n",
    "                dw += lambda_reg * np.sign(self.weights)\n",
    "\n",
    "            self.weights -= learning_rate * dw\n",
    "            self.bias -= learning_rate * db\n",
    "\n",
    "            loss = (error ** 2).mean()\n",
    "            if abs(prev_loss - loss) < threshold:\n",
    "                break\n",
    "            prev_loss = loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Converting Data\n",
    "Some features in a dataset are not of numerical type and are either categorical or boolean.  \n",
    "To get past this, we convert the columns by using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns from categorical/boolean to integer (use one-hot encoding)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Boolean to int\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == bool:\n",
    "        X[col] = X[col].astype(int)\n",
    "\n",
    "# One-hot encoding for categorical columns\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = X.values.astype(float)\n",
    "y = y.values.astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-train split\n",
    "Overfitting is one of the biggest problems in machine learning. Overfitting occurs when the model is trained to be very accurate on the given dataset but performs very poorly on a different but similar dataset.\n",
    "To check for overfitting, we split our dataset into test and train sets and check the accuracy/loss of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-Score Standardization\n",
    "Since some features might have much higher values than the others, for weights of similar magnitude, the model will mainly focus only on features with large values.  \n",
    "To overcome this, we standardize each feature using Z-Score Standardization so that all features are treated equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(X):\n",
    "    mean = X.mean(axis=0)\n",
    "    std = X.std(axis=0)\n",
    "    X_norm = (X - mean) / std\n",
    "    return X_norm, mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "x_train, x_mean, x_std = z_score(X_train)\n",
    "x_test = (X_test - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train, epochs=, learning_rate=, norm=, threshold=)\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"MSE loss: \", np.mean((y_pred - y_test) ** 2))\n",
    "\n",
    "indices = np.arange(len(y_test))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(indices, y_test, label='True Values', color='blue', marker='o')\n",
    "plt.plot(indices, y_pred, label='Predicted Values', color='red', marker='x')\n",
    "\n",
    "plt.xlabel('Data Points')\n",
    "plt.ylabel('Values')\n",
    "plt.title('True vs Predicted Values')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
